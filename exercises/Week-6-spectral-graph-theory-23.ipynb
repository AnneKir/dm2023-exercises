{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 6: Spectral Graph Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will work with graphs. Therefore, we need a python library for representing graphs. \n",
    "In particular, we will need `networkx`.\n",
    "Please run the following commands in your anaconda environment:\n",
    "\n",
    "```bash\n",
    "> pip install networkx\n",
    "```\n",
    "\n",
    "Afterwards, you should be able to restart your kernel and successfully run the following imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import networkx as nx\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Graphs and Their Spectrums\n",
    "\n",
    "In this exercise, we will look at the spectrum of a complete graph, a cycle graph (2-regular), and a random 3-regular graph, respectively.\n",
    "Read and run the code below and consider the eigenvalues plotted.\n",
    "\n",
    "1. Describe the differences in the eigenvalues for the three graphs\n",
    "2. Run the code a couple of times and observe what happens to the largest eigenvalue of the random 3-regular graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_eig(G): \n",
    "    \"\"\"\n",
    "        Takes a graph and returns the eigenvalues and eigenvectors of its normalized Laplacian matrix (L = D^{-1/2}(D-A)D^{-1/2})\n",
    "    \"\"\"\n",
    "    A  = nx.to_numpy_array(G)\n",
    "    D  = A.sum(axis=1)\n",
    "    D_ = 1. / np.sqrt(D)\n",
    "    D_ = np.diag(D_)\n",
    "    L  = D_ @ (np.diag(D)-A) @ D_\n",
    "    \n",
    "    lambdas, eigenvectors = np.linalg.eig(L)\n",
    "    \n",
    "    order = np.argsort(lambdas)\n",
    "    lambdas = lambdas[order]\n",
    "    eigenvectors = eigenvectors[:, order]\n",
    "    \n",
    "    return lambdas, eigenvectors\n",
    "\n",
    "G1 = nx.complete_graph(8)             # Complete graph\n",
    "G2 = nx.cycle_graph(8)                # Cycle graph\n",
    "G3 = nx.random_regular_graph(3, 8)    # Random 3-regular graph\n",
    "\n",
    "l1, e1 = graph_eig(G1)\n",
    "l2, e2 = graph_eig(G2)\n",
    "l3, e3 = graph_eig(G3)\n",
    "\n",
    "fig, ax = plt.subplots(1,4, figsize=(20, 5))\n",
    "\n",
    "ax[0].set_title(\"Complete Graph\", fontsize=16)\n",
    "nx.draw_circular(G1, ax=ax[0])\n",
    "ax[1].set_title(\"Cycle Graph\", fontsize=16)\n",
    "nx.draw_shell(G2, ax=ax[1])\n",
    "ax[2].set_title(\"3-regular Graph\", fontsize=16)\n",
    "nx.draw_shell(G3, ax=ax[2])\n",
    "\n",
    "ax[3].set_title(\"Eigenvalues\", fontsize=16)\n",
    "ax[3].set_xlabel('$i$', fontsize=14)\n",
    "ax[3].set_ylabel('Eigenvalues $\\lambda_i$', fontsize=14)\n",
    "ax[3].plot([0, 8], [8/7., 8/7.], 'y--', label=\"n/(n-1)\")\n",
    "ax[3].plot(l1,'r^-', label='Complete graph')\n",
    "ax[3].plot(l2,'b+-', label='Cycle graph')\n",
    "ax[3].plot(l3,'go-', label='3-regular graph')\n",
    "ax[3].set_ylim([-0.1,2.0])\n",
    "ax[3].legend()\n",
    "\n",
    "print(\"Sum of lambdas\")\n",
    "print(\"  G1  |  G2   |  G3  \")\n",
    "print(\"%.3f | %.3f | %.3f \" % (l1.sum(), l2.sum(), l3.sum()))\n",
    "print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all of them start with eigenvalue at zero  \n",
    "in the complete graph all the eig are the same afther the first. makes sense because the they are all equal kinda. same nhs  \n",
    "cycle all have same degree but not same nbs. increasing eigenvalues.  \n",
    "Different results for the 3-regular graf. It changes.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Spectral Properties of the normalized Graph Laplacian\n",
    "If we take a closer look at the spectrum above, we observe the following properties:\n",
    "\n",
    "1. $\\lambda_0 = 0$ for all graphs\n",
    "1. For all the graphs $\\sum_{i=0}^{n-1} \\lambda_i = n$\n",
    "1. For all the graphs, $\\lambda_1 \\leq \\frac{n}{n-1}$\n",
    "1. For all the graphs, $\\lambda_{n-1} \\geq \\frac{n}{n-1}$\n",
    "1. $*$ For the complete graph, $\\lambda_1, \\dots, \\lambda_{n-1} = \\frac{n}{n-1}$ \n",
    "\n",
    "**(Question with * might have a high probability for occuring in hand-in)**\n",
    "\n",
    "In the following, let $A$ be the adjacency matrix and $[D]_{i,i} = \\sum_{j}A_{i, j}$ is the degree matrix.\n",
    "We refer to eigenvalues $\\lambda_i$'s of the normalized laplacian $\\mathcal{L} = D^{-1/2}LD^{-1/2} = I - D^{-1/2}AD^{-1/2}$.\n",
    "\n",
    "We will now prove the five observations:\n",
    "\n",
    "**2.1) $\\lambda_0$ is always $0$**  \n",
    "Prove that the smallest eigenvalue $\\lambda_0 = 0$ for any graph.\n",
    "  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "If A is a symmetric matrix then all eigenvalues are $\\ge$ 0\n",
    "\n",
    "$\\mathcal{L} = D-A$, $xD^{1/2} \\bold{1}$,  $Lx=0$  \n",
    "Something about semidefinite"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**2.2) Sum of the spectrum**  \n",
    "Prove that if a graph $G$ with $n$ nodes is connected, i.e., there are no isolated nodes, then \n",
    "$$\n",
    "\\sum_{i=0}^{n-1} \\lambda_i = n\n",
    "$$\n",
    "\n",
    "_Hint:_ Recall [the relationship](https://en.wikipedia.org/wiki/Trace_%28linear_algebra%29#Eigenvalue_relationships) between eigenvalues and the trace. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a square matrix $A$ then $tr(A)=\\sum \\lambda_i$  \n",
    "  \n",
    "For the normalized Laplacian we have 1 down the diagonal if the node is connected to at least one other node, so $tr(\\mathcal{L}) = \\sum 1 = n$ and since it is square and symmetric $tr(\\mathcal{L}) = \\sum 1 = n = \\sum \\lambda_i$ "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.3) Upper bound on $\\lambda_1$**  \n",
    "Prove that if a graph $G$ is connected, then \n",
    "$$\n",
    "\\lambda_1 \\leq \\frac{n}{n-1}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know $\\lambda_0=0$ and that the sum needs to be n.  \n",
    "Divide by munbers we have left $1/(n-1)\\sum^{i-1}_1 \\lambda_i = n/(n-1)$, we use that they're sorted by size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**2.4) Lower bound on $\\lambda_{n-1}$**  \n",
    "Prove that if a graph $G$ is connected, then \n",
    "$$\n",
    "\\lambda_{n-1} \\geq \\frac{n}{n-1}\n",
    "$$\n",
    "  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same argument as before but flipped. We need to have at least one argument of this size to get up to $n$ and we know that $\\lambda_{n-1}$ is smallest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.5) Tight bound for complete graphs**  \n",
    "To prove that for all complete graphs, $\\lambda_0 = 0$ and $\\lambda_i = \\frac{n}{n-1}$ for $i=1, \\dots, n-1$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to prove $\\lambda_0 = 0$ and $\\lambda_i = \\frac{n}{n-1}$ for $i=1, \\dots, n-1$.  \n",
    "From the first ex we know $D^{1/2} \\times \\bold{1} = f$ is the first eigenvalue of the Laplacaian, and the rest should be orthogonal to this eigenvector. $x^Tf=0$.  \n",
    "We can also formulate as $\\sum_{i=1}^n x_if_i = \\sum_{i=1}^n x_i \\sqrt{d_i}$ where $d_i$ for degree. This sum is 0.  \n",
    "We have a complete graph where all ndoes have same degree: $d_i=n-1 \\forall i\\in[1,n]$  \n",
    "So we can plug in $\\sum_{i=1}^n x_if_i = \\sum_{i=1}^n x_i \\sqrt{n-1}$ and then take it out $  \\sqrt{n-1}\\sum_{i=1}^n x_i$.  \n",
    "The sum needs to be 0 and the values are all non-negative  \n",
    "\n",
    "We look into relationship between the vector x and the laplacian $[Lx]_i = x_i + \\sum_{j/=i}^n = \\frac{-1}{\\sqrt{d_j}\\sqrt{d_i}}\\cdot x_j $ we know all the degrees are the same so rewrite $x_i - \\sum_{}\\frac{1}{n-1}x_j$ (we know that it is n-1?), also take this out of the sum  \n",
    "$$\\frac{(n-1)x_i-\\sum_{j /= i}^n x_j }{n-1}$$  \n",
    "We can break down this. $$=\\frac{nx_i - \\sum_{j=1}^n x_j}{n-1}$$ \n",
    "We put $-x_i$ into the sum so we get the sum from before that runs over all $x$'s and We know that the sum is 0 from before, so we get $$\\frac{n}{n-1}x_i$$ which is what we wanted to prove...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Karate World\n",
    "\n",
    "In this exercise, we will look at Zachary's Karate club.\n",
    "Run the code below to visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "karate = nx.Graph()\n",
    "karate.add_edges_from([(1,2), (1,3), (1,4), (1,5), (1,6), (1,7), (1,8), (1,9), (1,11), (1,12), (1,13), (1,14), (1,18), (1,20), (1,22), (1,32), (2,3), (2,4), (2,8), (2,14), (2,18), (2,20), (2,22), (2,31), (3,4), (3,8), (3,9), (3,10), (3,14), (3,28), (3,29), (3,33), (4,8), (4,13), (4,14), (5,7), (5,11), (6,11), (6,17), (6,7), (7,17), (9,31), (9,33), (9,34), (10,34), (14,34), (15,33), (15,34), (16,33), (16,34), (19,33), (19,34), (20,34), (21,33), (21,34), (23,33), (23,34), (24,26), (24,28), (24,30), (24,33), (24,34), (25,26), (25,28), (25,32), (26,32), (27,30), (27,34), (28,34), (29,32), (29,34), (30,33), (30,34), (31,33), (31,34), (32,33), (32,34), (33,34)])\n",
    "fixed_positions = {1:(10.74,4.07),2:(9.76,6.48),3:(8.39,5.21),4:(10.37,1.98),5:(12.30,5.61),6:(13.31,3.28),7:(13.28,5.00),8:(8.41,7.06),9:(6.72,4.31),10:(5.77,1.38),11:(12.30,2.72),12:(12.75,4.05),13:(11.32,2.41),14:(8.70,2.88),15:(3.33,0.63),16:(1.88,2.01),17:(13.92,4.05),18:(10.77,5.61),19:(0.69,6.40),20:(9.05,1.38),21:(0.34,4.63),22:(11.56,6.22),23:(5.24,0.34),24:(1.88,7.49),25:(5.11,6.80),26:(4.31,8.52),27:(2.14,0.32),28:(3.65,6.64),29:(6.03,5.24),30:(0.77,2.91),31:(7.01,2.43),32:(6.61,7.86),33:(4.60,4.52),34:(4.39,2.91)}\n",
    "nx.draw(karate,pos=fixed_positions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lk, ek = graph_eig(karate)\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(lk, 'b-o')\n",
    "ax.set_xlabel(\"$i$\")\n",
    "ax.set_ylabel(\"$\\lambda_i$\")\n",
    "ax.set_title(\"Karate spectrum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot of the spectrum looks as expected. Let's \n",
    "look at the properties of the eigenvectors of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 3, figsize=(16, 8))\n",
    "ek_ = np.around(ek, decimals=1)\n",
    "for k in np.arange(0,6): \n",
    "    i, j = k // 3, k % 3\n",
    "    ncs = ek_[:,k]\n",
    "    nx.draw(karate, ax=ax[i, j], cmap=plt.get_cmap('RdBu'), node_color=ncs, pos=fixed_positions, with_labels=True)\n",
    "    ax[i, j].set_title(\"k = %i\" % k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.1**  \n",
    " - What happens to the node coloring as $k$ increases? \n",
    " - Do you observe anything surprising?\n",
    " - How does what we see here relate to Spectral Clustering?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k is how often you round?  \n",
    "\n",
    "How accurate do we want our analysis to be? Sometimes it is not feasible to go to billion decimal points. What is feasible for our data and also still accurate. It is possible to overfit. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "karate2 = nx.Graph()\n",
    "karate2.add_edges_from([(1,2), (1,3), (1,4), (1,5), (1,6), (1,7), (1,8), (1,11), (1,12), (1,13), (1,14), (1,18), (1,20), (1,22), (2,3), (2,4), (2,8), (2,14), (2,18), (2,20), (2,22), (3,4), (3,8), (3,14), (4,8), (4,13), (4,14), (5,7), (5,11), (6,11), (6,17), (6,7), (7,17), (9,31), (9,33), (9,34), (10,34), (15,33), (15,34), (16,33), (16,34), (19,33), (19,34), (21,33), (21,34), (23,33), (23,34), (24,26), (24,28), (24,30), (24,33), (24,34), (25,26), (25,28), (25,32), (26,32), (27,30), (27,34), (28,34), (29,32), (29,34), (30,33), (30,34), (31,33), (31,34), (32,33), (32,34), (33,34)])\n",
    "fixed_positions = {1:(10.74,4.07),2:(9.76,6.48),3:(8.39,5.21),4:(10.37,1.98),5:(12.30,5.61),6:(13.31,3.28),7:(13.28,5.00),8:(8.41,7.06),9:(6.72,4.31),10:(5.77,1.38),11:(12.30,2.72),12:(12.75,4.05),13:(11.32,2.41),14:(8.70,2.88),15:(3.33,0.63),16:(1.88,2.01),17:(13.92,4.05),18:(10.77,5.61),19:(0.69,6.40),20:(9.05,1.38),21:(0.34,4.63),22:(11.56,6.22),23:(5.24,0.34),24:(1.88,7.49),25:(5.11,6.80),26:(4.31,8.52),27:(2.14,0.32),28:(3.65,6.64),29:(6.03,5.24),30:(0.77,2.91),31:(7.01,2.43),32:(6.61,7.86),33:(4.60,4.52),34:(4.39,2.91)}\n",
    "nx.draw(karate2,pos=fixed_positions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3.2:**  \n",
    "In the above graph, we have cut some edges to form two connected components.\n",
    "What will happen to the spectrum of this simpler graph?\n",
    "\n",
    "If you want, you can try to plot the spectrum and see if you were right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Plot spectrum.\n",
    "# lambdas, eig_vectors = graph_eig(karate2)\n",
    "\n",
    "lk, ek = graph_eig(karate2)\n",
    "fig, ax = plt.subplots(1,1)\n",
    "ax.plot(lk, 'b-o')\n",
    "ax.set_xlabel(\"$i$\")\n",
    "ax.set_ylabel(\"$\\lambda_i$\")\n",
    "ax.set_title(\"Karate spectrum\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They look very similar, the ties between the two sections were not that dense, compared to the graph, so removing them doesnt change the features too much\n",
    "\n",
    "Can be a problem for spectral analysis, the spectrum can look very similar even for graphs that can have some distinct feature..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: Other spectrums\n",
    "\n",
    "Please find the spectrums of different symmetric matrices, computed from the karate graph, below. \n",
    "Write code to plot them and explain how the spectrums differ.\n",
    "\n",
    "In particular, what can you say about the sum of the spectrums and the bounds on the eigenvalues?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns eigenvalues of the adjacency matrix of G.\n",
    "lA = nx.adjacency_spectrum(karate)\n",
    "lA = np.sort(lA)\n",
    "\n",
    "# Returns eigenvalues of the Laplacian of G\n",
    "lL = nx.laplacian_spectrum(karate)\n",
    "lL = np.sort(lL)\n",
    "\n",
    "# Return eigenvalues of the normalized Laplacian of G\n",
    "lN = nx.normalized_laplacian_spectrum(karate)\n",
    "lN = np.sort(lN)\n",
    "\n",
    "# TODO plot the spectrums\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "\n",
    "ax.set_title(\"Eigenvalues\", fontsize=16)\n",
    "ax.set_xlabel('$i$', fontsize=14)\n",
    "ax.set_ylabel('Eigenvalues $\\lambda_i$', fontsize=14)\n",
    "# ax.plot([0, 8], [8/7., 8/7.], 'y--', label=\"n/(n-1)\")\n",
    "ax.plot(lA,'r^-', label='Adjacency')\n",
    "ax.plot(lL,'b+-', label='Laplacian')\n",
    "ax.plot(lN,'go-', label='normalized')\n",
    "# ax.set_ylim([-0.1,2.0])\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(20, 5))\n",
    "ax[0].set_title(\"Eigenvalues\", fontsize=16)\n",
    "ax[0].set_xlabel('$i$', fontsize=14)\n",
    "ax[0].set_ylabel('Eigenvalues $\\lambda_i$', fontsize=14)\n",
    "# [0]ax.plot([0, 8], [8/7., 8/7.], 'y--', label=\"n/(n-1)\")\n",
    "ax[0].plot(lA,'r^-', label='Adjacency')\n",
    "ax[1].plot(lL,'b+-', label='Laplacian')\n",
    "ax[2].plot(lN,'go-', label='normalized Laplacian')\n",
    "# [0]ax.set_ylim([-0.1,2.0])\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "ax[2].legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We dont start at 0 with the adjacency matrix.  \n",
    "Comparability goes down ?  \n",
    "\n",
    "Lapalacian starts at 0, non-negactive values, nice. we dont know where we end up  \n",
    "\n",
    "Normalized Laplacian ends at 1???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: Spectral Clustering\n",
    "In this exercise, we are going to implement the spectral clustering algorithm. \n",
    "Recal, that the algorithm has three steps:\n",
    "\n",
    "1. Construct nearest-neighbor-graph of the data.\n",
    "2. Do the eigen-decomposition of the graph Laplacian\n",
    "3. Use K-means to cluster the features of the eigenvectors corresponding to the smallest non-zero eigenvalues\n",
    "\n",
    "Below, we will make code that allows us to test performance of different Laplacians.\n",
    "But first we need some data to cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.datasets\n",
    "X, y = sklearn.datasets.make_moons(n_samples=200, shuffle=True, noise=.06)\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.scatter(*(X.T), c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how K-Means it self does not work on this data-set, as opposed to Spectral Clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering, KMeans\n",
    "\n",
    "clustering = SpectralClustering(n_clusters=2, n_neighbors=20, affinity='nearest_neighbors').fit(X)\n",
    "kmeans = KMeans(2).fit(X)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].set_title(\"K-Means\")\n",
    "ax[0].scatter(*(X.T), c=kmeans.labels_)\n",
    "ax[1].set_title(\"Spectral Clustring\")\n",
    "ax[1].scatter(*(X.T), c=clustering.labels_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to implement Spectral Clustering.\n",
    "You may use the [NearestNeighbors](https://scikit-learn.org/stable/modules/neighbors.html) algorithm from sklearn to speed up things a bit.\n",
    "\n",
    "You can try with different Laplacians if you want.\n",
    "\n",
    "Hints to make it work:\n",
    " - Use weighted adjacency matrix (mode='distance' for `kneighbors_graph`)\n",
    " - n_neighbors=2 and 3 eigenvectors worked well for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Comstruct nearest neighbor graph.\n",
    "nbrs = NearestNeighbors(n_neighbors=20)\n",
    "nbrs = nbrs.fit(X)\n",
    "\n",
    "moons = nx.from_scipy_sparse_array(nbrs.kneighbors_graph(X, mode='distance'))\n",
    "\n",
    "# Plot the graph that we just computed.\n",
    "nx.draw(moons, pos=X, node_size=30, node_color=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import k_means\n",
    "\n",
    "# TODO: Do spectral clustering. \n",
    "y_clust = np.zeros(X.shape[0])\n",
    "\n",
    "L = nx.normalized_laplacian_matrix(moons).todense()\n",
    "\n",
    "l,e = np.linalg.eig(L)\n",
    "order = np.argsort(L)\n",
    "l = l[order]\n",
    "print(l)\n",
    "e = e[:, order]\n",
    "\n",
    "sel = np.arange(len(l))[np.where(l > 1e-15)][:3]\n",
    "\n",
    "X_ = e[:, sel]\n",
    "\n",
    "best_interia = float('inf')\n",
    "y_clust=None\n",
    "for i in range(10):\n",
    "    _, y_, interia, *_ = k_means(X_,2)\n",
    "    if interia < best_interia:\n",
    "        y_clust = y_\n",
    "        best_interia = interia\n",
    "\n",
    "# END TODO\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "ax[0].plot(l)\n",
    "ax[0].set_title(\"Spectrum of graph\")\n",
    "ax[1].scatter(*(X.T), c=y)\n",
    "ax[1].set_title(\"Labels\")\n",
    "ax[2].scatter(*(X.T), c=y_clust)\n",
    "ax[2].set_title(\"Spectral clusters\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
